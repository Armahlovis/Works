<!-- TODO 7: Add the Contact Me and About Me page links -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Notes</title>
    <title>Linear Algebra</title>
   
</head>
<h1>Deep Learning  </h1>
<h3>Linear Algebra</h3>
<hr>

<ol>
<li><p>Scalers, Vectors and Tensors are ways to represent data. Tensor is an array with more than 2 axes </p></li>
<li><p>Inverse operation on a matrics is a theoritical concept rarely used in practise  </p></li>
<li><p>Range of a matrix or column space provides a way to test if a solution to a matrix equation exist </p></li>
<li><p>Euclidean norm(L2 norm) calculates the length of a vector from the origin to a given point</p></li>
<li><p>L1 norm helps to descriminate between zero elements vectors from those with non zero elements</p></li>
<li><p>Max norm returns the absolute value of the highest number in a vector</p></li>
<li><p>Diagonal matrics provides a less expensive way to derive an ML algorithm</p></li>
<li><p>Symmetric matrix arise when the entries are generated by some function with two arguments that is not affected by change in order of the argument</p></li>
<li><p>Orthogonal matrix provides a cheaper way to compute the inverse of a matrix</p></li>
<li><p>Eigen decomposition breaks a matrix into eigen values and vectors so that they can easily be analyzed. For example a matrix with all zero eigen values are singular.</p></li>
<li><p>The eigendecomposition of a real symmetric matrix can be used to optimize a quadratic function (F=X^TAX ||x||2=1). The maximum and minimum values within the constraint region are the maximum and minimum eigen values</p></li>
<li><p>Positive definite matrices(eigen values are greater than 0),positive semi definite(eigen values>=0) are useful because it provides a definite way to tell if a given vector is a zero vector</p></li>
<li><p>Singular Value Decomposition is another way to factorize matrices that is more applicable</p></li>
<li><p>The most useful feature of SVD is that it can partially generalize matrics inversion to non square matrices</p></li>

</ol>




    


<body>
    
</body>
</html>